---
title: "p8105_hw3_ww2579"
author: "Wenzhao Wu"
date: "10/10/2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(p8105.datasets)
library(readxl)
data("ny_noaa")
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `rcol(instacart)` columns.

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most item from?

```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Let's make a plot

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 1000) %>%  
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Apples vs ice cream.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


## Problem 2

Load, tidy, and wrangle the data.

```{r}
tidied_df = 
  read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_min",
    values_to = "activity_counts",
    names_prefix = "activity_") %>%
  mutate(
    dow = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend"),
    day = factor(day),
    dow = factor(dow),
    activity_min = as.numeric(activity_min))

tidied_df
```
This dataset contains `r nrow(tidied_df)` rows and `r ncol(tidied_df)` columns. 

It collects data of activity counts for each minute of a 24-hour day for 35 days (i.e. 5 weeks), with a total number of observations of `r nrow(tidied_df)`.

There are variables `r ls(tidied_df)` included.

Data summary in an "untidy" table.

```{r}
day_activity = tidied_df %>% 
  group_by(week, day) %>%
  summarise(activity_per_day = sum(activity_counts)) 

xtabs(activity_per_day ~ week + day, data = day_activity)
```

After aggregating across minutes for each day, there are total `r nrow(day_activity)` observations. One standing-out feature is that on Saturdays of week 4 and 5, the activity counts are both 1440 units per day, which is the lowest sum of value.


Make a single-panel plot.

```{r}
activity_plot = 
  tidied_df %>%
  ggplot(aes(x = activity_min, y = activity_counts, group = day_id, color = day_id),alpha = 0.4) +
  geom_point(size = 0.1, alpha = 0.4) +
  geom_line(alpha = 0.5) +
  scale_x_continuous(
    breaks = seq(1,1440,60)
  ) +
  scale_y_continuous(
    trans = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

activity_plot
```

Interpretations:
From the graph above we can see that most of the data are below 2500 units of activity counts within one day. In terms of the overall trend, the activity counts are staying relatively low for about the first 300 minutes (i.e. from midnight to 5am). There are much more extreme values during the day, some of which are concentrated at 1201 min (i.e. 8pm). Then the activity counts decrease after 1321 min (i.e. 10pm). There is no apparent association observed between day_id and activity counts, since lines are quite overlapped.


## Problem 3

```{r}
ny_noaa = ny_noaa %>%
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>%
  mutate(month = factor(month),
         tmax = as.numeric(tmax),
         tmin = as.numeric(tmin))
ny_noaa
```

The most commonly observed values for snowfall (mm). 

```{r}
ny_noaa %>%
  count(snow) %>%
  arrange(desc(n))
```

The most commonly observed value is "0" with a frequency of 2008508.


Jan vs July.

```{r}
jj_plot = ny_noaa %>%
  filter(month %in% c("1","7")) %>%
  group_by(month,year,id) %>%
  summarize(
    mean_tmax = (mean(tmax,na.rm = TRUE))) %>%
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_point() +
  geom_line() +
  geom_smooth(se = F) +
  facet_grid(~month) +
  labs(
    x = "Year",
    y = "Mean_Tmax (tenths of degrees C)") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        legend.position = "none")

jj_plot

```

Interpretations:
There is no obvious increasing or decreasing trend observed across years. Both means of tmax in January and July display a "zigzag" graph, of which the data show a greater fluctuation in January during this time period. Also, it can be easily seen from the graph that the mean max temperature in July is significantly higher than that in January. In 1994 and 2004, the average max temperatures in January seem to have a bigger drop from the previous years when compared to other years. However, it is not easy to tell from this figure about which stations usually having higher or lower temperatures. In addition, outliers might include some extreme values, such as the one in July in 1988, and the one in January in 1982. 


Make a two-panel plot. 

```{r}
mean_temp_plot = ny_noaa %>%
  ggplot(aes(x = tmin, y = tmax)) +
  geom_point() +
  geom_hex() +
  labs(
    title = "Max_Temp vs Min_Temp",
    x = "Min_Temp (tenths of degrees C)",
    y = "Max_Temp (tenths of degrees C)")

mean_temp_plot

snow_plot = 
  ny_noaa %>%
  filter(snow > 0  & snow < 100 ) %>%
  ggplot(aes(x = year, y = snow, group = year, colour = year)) +
  geom_violin(aes(fill = year), alpha = .5) + 
  stat_summary(fun = "mean", color = "blue")+
  labs(x = "Year", y = "Snow (mm)", title = "Distribution of Snowfall by Year")

snow_plot

mean_temp_plot+snow_plot
```

Interpretations:
The max temperature and min temperature are proportional to each other as the graph shown above. The snowfall (mm) in NYC is mainly distributed below 37.5 mm (within the interval (0,100)) and staying stable over years. 
