---
title: "p8105_hw3_ww2579"
author: "Wenzhao Wu"
date: "10/10/2020"
output: github_document
---

```{r setup}
library(tidyverse)
library(p8105.datasets)
library(readxl)
data("ny_noaa")

knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `rcol(instacart)` columns.

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most item from?

```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

Let's make a plot

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 1000) %>%  
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!

```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Apples vs ice cream.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


## Problem 2

Load, tidy, and wrangle the data.

```{r}
tidied_df = 
  read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_min",
    values_to = "activity_counts",
    names_prefix = "activity_") %>%
  mutate(
    dow = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend"),
    day = factor(day),
    dow = factor(dow),
    activity_min = as.numeric(activity_min))

tidied_df
```
This dataset contains `r nrow(tidied_df)` rows and `r ncol(tidied_df)` columns. 

It collects data of activity counts for each minute of a 24-hour day for 35 days (i.e. 5 weeks), with a total number of observations of `r nrow(tidied_df)`.

There are variables `r ls(tidied_df)` included.

Data summary.

```{r}
day_activity = 
  tidied_df %>%
  group_by(week, day, day_id) %>%
  summarise(activity_per_day = sum(activity_counts)) %>%
  knitr::kable()

day_activity
```

After aggregating across minutes for each day, there are total `r nrow(day_activity)` observations. One standing-out feature is that on Saturdays of week 4 and 5, the activity counts are both 1440 per day.


Make a single-panel plot.

```{r}
plot_accel = 
  tidied_df %>%
  ggplot(aes(x = activity_min, y = activity_counts, group = day_id, color = day_id),alpha = 0.5) +
  geom_line() +
  scale_y_continuous(
    trans = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

plot_accel
```
